{% set name = "transformers" %}
{% set version = "4.45.2" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/huggingface/transformers/archive/refs/tags/v{{ version }}.tar.gz
  sha256: 9bd4891514f5dd9446ece8511caba6a7c677de7cb333084e03ad0b5345d57c95

build:
  skip: True  # [py<38]
  number: 0
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv
  entry_points:
    - transformers-cli=transformers.commands.transformers_cli:main

requirements:
  host:
    - pip
    - python
    - setuptools
    - wheel
  run:
    - python
    # datasets required for transformers-cli.
    - datasets !=2.5.0
    - importlib-metadata
    - filelock
    - huggingface_hub >=0.23.2,<1
    - numpy >=1.17
    - packaging >=20.0
    - pyyaml >=5.1
    - regex !=2019.12.17
    - requests
    - safetensors >=0.4.1
    - tokenizers >=0.20,<0.21
    - tqdm >=4.27
  run_constrained:
    - blas * openblas     # [osx and x86_64]

test:
  source_files:
    - .
  imports:
    - transformers
    - transformers.benchmark
    - transformers.commands
    - transformers.data
    - transformers.kernels
    - transformers.models
    - transformers.pipelines
    - transformers.utils
  requires:
    - pip
    # to satisfy `transformers-cli --help` because it raises a warning of missing pytorch/tensorflow/flax for models.
    - pytorch >=2
    - bs4
    # NLTK recent 3.9 release breaks FastSpeechConformer2 tests,
    # see https://github.com/huggingface/transformers/pull/33301
    - nltk <=3.8.1
    - parameterized
    - psutil
    - pydantic
    - pytest >=7.2.0,<8.0.0
    - sentencepiece >=0.1.91,!=0.1.92
  # Undeclared as testing deps
    - pillow >=10.0.1,<=15.0
    - huggingface_accelerate >=0.26.0
  commands:
    - pip check
    - transformers-cli --help
    # Ignoring tests in all subdirectories.
    {% set ignore_tests = " --ignore=tests/agents" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/benchmark" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/bettertransformer" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/deepspeed" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/extended" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/fixtures" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/fsdp" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/generation" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/models" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/optimization" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/peft_integration" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/pipelines" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/quantization" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/repo_utils" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/sagemaker" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/tokenization" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/trainer" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/utils" %}
    # These tests require librosa, missing from defaults
    {% set skip_tests = "return_timestamps_ctc_fast" %}
    {% set skip_tests = skip_tests + " or chunking_fast" %}
    {% set skip_tests = skip_tests + " or small_model_pt" %}
    {% set skip_tests = skip_tests + " or from_pretrained_low_cpu_mem_usage_measured" %}
    # pytorch dynamo unsupported on Python 3.12
    {% set skip_tests = skip_tests + " or warn_if_padding_and_no_attention_mask" %}  # [py>311]
    # Requires cxx compiler
    {% set skip_tests = skip_tests + " or test_torch_compile_fullgraph" %}
    # Tensorboard install conflicts
    {% set skip_tests = skip_tests + " or test_word_heuristic_leading_space" %}

    - pytest tests -k "not ({{ skip_tests }})" {{ ignore_tests }}

about:
  home: https://github.com/huggingface/transformers
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow
  description: |
    Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.

    These models can be applied on:

    - üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.
    - üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.
    - üó£Ô∏è Audio, for tasks like speech recognition and audio classification.

    Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.
  doc_url: https://huggingface.co/docs/transformers/index
  dev_url: https://github.com/huggingface/transformers

extra:
  recipe-maintainers:
    - mxr-conda
    - roccqqck
    - oblute
    - rluria14
    - ndmaxar
    - setu4993
    - hadim
    - wietsedv
  skip-lints:
    - python_build_tool_in_run
