{% set name = "transformers" %}
{% set version = "4.18.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 16f7751c44f31d8f9a3811bccd80f1995e1cb0ffd9b7de60ef6ede2ab90a6fd4

build:
  skip: True  # [py<36 or win32]
  number: 1
  script: {{ PYTHON }} -m pip install . -vv
  entry_points:
    - transformers-cli=transformers.commands.transformers_cli:main

requirements:
  host:
    - pip
    - python
    - setuptools
    - wheel
  run:
    - python
    - dataclasses  # [py<37]
    - filelock
    - huggingface_hub >=0.1.0,<0.10.1
    - importlib_metadata  # [py<38]
    - numpy >=1.17
    - packaging >=20.0
    - pytorch
    - pyyaml >=5.1
    - regex !=2019.12.17
    - requests
    - sacremoses
    - tokenizers >=0.11.1,!=0.11.3,<0.13
    - tqdm >=4.27

test:
  requires:
    - pip
    # torch 1.6.0 requires future
    - future  # [win64 and py==37]
  imports:
    - transformers
    - transformers.benchmark
    - transformers.commands
    - transformers.data
    - transformers.data.datasets
    - transformers.data.metrics
    - transformers.data.processors
    - transformers.models
    - transformers.pipelines
    - transformers.sagemaker
    - transformers.utils
  commands:
    - pip check
    - transformers-cli --help

about:
  home: https://github.com/huggingface/transformers
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  license_url: https://github.com/huggingface/transformers/blob/main/LICENSE
  summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch
  description: |
    Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.

    These models can be applied on:

    - üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.
    - üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.
    - üó£Ô∏è Audio, for tasks like speech recognition and audio classification.
    
    Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.
  doc_url: https://huggingface.co/transformers/
  doc_source_url: https://github.com/huggingface/transformers/tree/main/docs/source
  dev_url: https://github.com/huggingface/transformers

extra:
  recipe-maintainers:
    - mxr-conda
    - roccqqck
    - oblute
    - rluria14
    - ndmaxar
    - setu4993
    - hadim
    - wietsedv
