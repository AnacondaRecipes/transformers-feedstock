{% set name = "transformers" %}
{% set version = "4.57.1" %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  url: https://github.com/huggingface/{{ name }}/archive/refs/tags/v{{ version }}.tar.gz
  sha256: 425e9f2e4281fe977be496902b5b4cd79c2bf0a6dab9e516bc16d2c56ab2f487

build:
  number: 0
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv
  entry_points:
    - transformers-cli=transformers.commands.transformers_cli:main
  skip: True  # [py<39]

requirements:
  host:
    - pip
    - python
    - setuptools
    - wheel
  run:
    - python
    # We need either this pin or pyarrow<21.0.0
    - datasets >=2.15.0
    - filelock
    - huggingface_hub >=0.34.0,<1.0
    - numpy >=1.17
    - packaging >=20.0
    - pyyaml >=5.1
    - regex !=2019.12.17
    - requests
    - safetensors >=0.4.3
    - tokenizers >=0.22.0,<=0.23.0
    - tqdm >=4.27
  run_constrained:
    # Duplicates are commented to avoid build errors!!!
    # ja(Japanese) related
    - fugashi >=1.0 
    - ipadic >=1.0.0,<2.0 
    - unidic_lite >=1.0.7 
    - unidic >=1.0.7
    - sudachipy >=0.6.6 
    - sudachidict_core >=20220729 
    - rhoknp >=1.1.0,<1.3.1   
    # sklearn related
    - scikit-learn
    # tf(TensorFlow) related
    - tensorflow >2.9,<2.16 
    - onnxconverter-common
    - tf2onnx 
    - tensorflow-text <2.16
    - keras-nlp >=0.3.1,<0.14.0  
    # tf-cpu related
    - keras >2.9,<2.16
    - tensorflow-cpu >2.9,<2.16
    #- onnxconverter-common
    #- tf2onnx
    #- tensorflow-text <2.16
    #- keras-nlp >=0.3.1,<0.14.0  
    - tensorflow-probability <0.24
    # torch related
    - pytorch >=2.2
    - accelerate >=0.26.0
    # accelerate related
    #- accelerate >=0.26.0
    # hf_xet related
    - hf_xet
    # retrieval related
    - faiss-cpu  # [unix]
    # flax related
    - jax >=0.4.1,<=0.4.13  # [unix]
    - jaxlib >=0.4.1,<=0.4.13  # [unix]
    - flax >=0.4.1,<=0.7.0  # [unix]
    - optax >=0.0.8,<=0.1.4  # [unix]
    # SciPy >= 1.13.0 is not supported with the current jax pin (`jax>=0.4.1,<=0.4.13`)
    - scipy <1.13.0  # [unix]
    # ftfy related
    - ftfy
    # onnxruntime related
    - onnxruntime >=1.4.0 
    - onnxruntime-tools >=1.4.2   
    # onnx related
    #- onnxconverter-common
    #- tf2onnx
    #- onnxruntime >=1.4.0
    # modelcreation related
    - cookiecutter ==1.7.3
    # sagemaker related
    - sagemaker >=2.31.0
    # deepspeed related
    - deepspeed >=0.9.3
    #- accelerate >=0.26.0
    # optuna related
    - optuna
    # ray related
    - ray >=2.7.0
    # sigopt related
    - sigopt
    # hub-kernels related
    - kernels >=0.6.1,<=0.9
    # integrations related
    #- kernels >=0.6.1,<=0.9
    #- optuna
    #- ray >=2.7.0
    # serving related
    - openai >=1.98.0
    - pydantic >=2
    - uvicorn
    - fastapi
    - starlette
    #- pytorch >=2.2
    #- accelerate >=0.26.0
    # audio, tf-speech, flax-speech related
    - librosa
    - pyctcdecode >=0.4.0
    - phonemizer
    - kenlm
    # speech, torch-speech related
    - torchaudio
    #- librosa
    #- pyctcdecode >=0.4.0
    #- phonemizer
    #- kenlm
    # vision related
    - pillow >=10.0.1,<=15.0
    # timm related
    - timm <=1.0.19,!=1.0.18
    # torch-vision related
    - torchvision
    #- pillow >=10.0.1,<=15.0
    # natten related
    - natten >=0.14.6,<0.15.0
    # codecarbon related
    - codecarbon >=2.8.1
    # video related
    - av
    # num2words related
    - num2words
    # sentencepiece related
    - sentencepiece >=0.1.91,!=0.1.92
    - protobuf
    # tiktoken related
    - tiktoken
    - blobfile
    # mistral-common related
    - mistral-common >=1.6.3
    - opencv-python
    # chat_template related
    - jinja2 >=3.1.0
    # torchhub related
    - importlib_metadata
    #- sentencepiece >=0.1.91,!=0.1.92
    #- pytorch >=2.2
    # benchmark related
    - optimum-benchmark >=0.3.0
    # open-telemetry related
    - opentelemetry-api
    - opentelemetry-exporter-otlp
    - opentelemetry-sdk

test:
  source_files:
    - .
  imports:
    - transformers
    - transformers.activations
    - transformers.audio_utils
    - transformers.cache_utils
    - transformers.commands
    - transformers.configuration_utils
    - transformers.convert_slow_tokenizer
    - transformers.generation
    - transformers.image_processing_base
    - transformers.image_processing_utils_fast
    - transformers.image_utils
    - transformers.models
    - transformers.pipelines
    - transformers.processing_utils
    - transformers.tokenization_utils
    - transformers.tokenization_utils_base
    - transformers.tokenization_utils_fast
    - transformers.utils
  requires:
    - pip
    # to satisfy `transformers-cli --help` because it raises a warning of missing pytorch/tensorflow/flax for models.
    - pytorch >=2.2  # [not (osx and arm64)]
    # PBP is using the GPU version for some reason:
    - pytorch =2.7.0=cpu_openblas_*  # [osx and arm64]
    - bs4
    # NLTK recent 3.9 release breaks FastSpeechConformer2 tests,
    # see https://github.com/huggingface/transformers/pull/33301
    - nltk <=3.8.1
    - parameterized
    - psutil
    - pydantic >=2
    - pytest >=7.2.0,<8.0.0
    - sentencepiece >=0.1.91,!=0.1.92
    - rich
  # Undeclared as testing deps
    - pillow >=10.0.1,<=15.0
    - huggingface_accelerate >=0.26.0
  commands:
    - export PYTORCH_ENABLE_MPS_FALLBACK=1  # [osx]
    - pip check
    - transformers-cli --help
    # Ignoring tests in all subdirectories.
    {% set ignore_tests = " --ignore=tests/agents" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/benchmark" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/bettertransformer" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/deepspeed" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/extended" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/fixtures" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/fsdp" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/generation" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/models" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/peft_integration" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/pipelines" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/quantization" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/repo_utils" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/sagemaker" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/tensor_parallel" %}  #  [win or osx]
    {% set ignore_tests = ignore_tests + " --ignore=tests/tokenization" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/trainer" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/utils" %}
    # torch.compile not available until pytorch 2.6
    {% set ignore_tests = ignore_tests + " --ignore=tests/test_pipeline_mixin.py" %}  # [py>312]
    #     mode: ValidationMode = ValidationMode.test,
    # E   NameError: name 'ValidationMode' is not defined
    {% set ignore_tests = ignore_tests + " --ignore=tests/test_tokenization_mistral_common.py" %}

    # These tests require librosa, missing from defaults
    {% set skip_tests = "return_timestamps_ctc_fast" %}
    {% set skip_tests = skip_tests + " or chunking_fast" %}
    {% set skip_tests = skip_tests + " or input_parameter_passthrough" %}
    {% set skip_tests = skip_tests + " or pipeline_assisted_generation" %}
    {% set skip_tests = skip_tests + " or test_return_timestamps_ctc_fast" %}
    {% set skip_tests = skip_tests + " or from_pretrained_low_cpu_mem_usage_measured" %}
    # pytorch dynamo unsupported on Python 3.12
    {% set skip_tests = skip_tests + " or warn_if_padding_and_no_attention_mask" %}  # [py>311]
    # Requires cxx compiler
    {% set skip_tests = skip_tests + " or test_torch_compile_fullgraph" %}
    # Tensorboard install conflicts
    {% set skip_tests = skip_tests + " or test_word_heuristic_leading_space" %}

    # Small floating point rounding errors.
    {% set skip_tests = skip_tests + " or small_model_pt" %}
    {% set skip_tests = skip_tests + " or small_model_pt_fp16" %}
    {% set skip_tests = skip_tests + " or small_model_pt_seq2seq" %}
    {% set skip_tests = skip_tests + " or torch_float16_pipeline" %}
    {% set skip_tests = skip_tests + " or return_dict_in_generate" %}
    {% set skip_tests = skip_tests + " or stop_sequence_stopping_criteria" %}

    # Require Mac OS 14
    {% set skip_tests = skip_tests + " or return_timestamps_in_init" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or torch_bfloat16_pipeline" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or consistent_batching_behaviour" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or consistent_batching_behaviour" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or pipeline_length_setting_warning" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or small_chat_model_continue_final_message" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or small_chat_model_continue_final_message_override" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or small_chat_model_pt" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or small_chat_model_with_dataset_pt" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or small_chat_model_with_iterator_pt" %}  # [osx and arm64]
    {% set skip_tests = skip_tests + " or test_en_to_de_pt" %}  # [osx]

    # TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType
    {% set skip_tests = skip_tests + " or test_no_offset_tokenizer" %}  # [linux and aarch64]

    - pytest tests -k "not ({{ skip_tests }})" {{ ignore_tests }}

about:
  home: https://github.com/huggingface/transformers
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow
  description: |
    Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.

    These models can be applied on:

    - üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.
    - üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.
    - üó£Ô∏è Audio, for tasks like speech recognition and audio classification.

    Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.
  doc_url: https://huggingface.co/docs/transformers/index
  dev_url: https://github.com/huggingface/transformers

extra:
  recipe-maintainers:
    - mxr-conda
    - roccqqck
    - oblute
    - rluria14
    - ndmaxar
    - setu4993
    - hadim
    - wietsedv
  skip-lints:
    - python_build_tool_in_run
